{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting unique IDs #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IDS = \"\"\"P173506 P176215 P090872 P163545 P157303 P117558 P169753 P156421 P126661 P003112 P003074 P003116 P096414\n",
    "P128452 P163835 P083055 P126890 P084955 P120709 P003034 P003024 P003008 P124720 P083882 P085984 P101745 P165090\n",
    "P057293 P086874 P504532 P091990 P003012 P003014 P003018 P003026 P003031 P003035 P003044 P003087 P157922 P149233\n",
    "P172341 P071144 P098842 P088751 P082516 P092724 P174026 P126214 P166763 P153085 P157114 P126088 P159037 P125509\n",
    "P173825 P180495 P145196 P086294 P156208 P081850 P096305 P115642 P104497 P120898 P104041 P117382 P177460 P083813\n",
    "P127437 P178684 P166110 P157864 P153836 P145965 P131027 P117434 P122251 P092537 P168756 P178816 P113977 P125677\n",
    "P111621 P152903 P510575 P120647 P115318 P506815 P161877 P129713 P508410 P091092 P155266 P160806 P098187 P124072\n",
    "P106982 P129594 P150148 P105729 P126683 P150651 P145747 P145554 P003096 P003051 P003015 P003022 P003082 P078658\n",
    "P075660 P088619 P108905 P057296 P118658 P073864 P178176 P003045 P171762 P086750 P162517 P003098 P507861 P100620\n",
    "P178642 P149049 P173415 P003120 P003053 P003041 P003006 P003010 P126115 P166004 P147555 P003089 P003011 P003016\n",
    "P003020 P003028 P003108 P003042 P003050 P128887 P160182 P003058 P003019 P506438 P179292 P161602 P171141 P003091\n",
    "P003033 P003017 P003025 P162837 P003048 P169021 P003055 P003040 P003027 P003037 P003009 P003129 P003132 P003043\n",
    "P082443 P003054 P087649 P181063 P163962 P159160 P160612 P122229 P160320 P003021 P003029 P086214 P003036 P150874\n",
    "P003013 P003007 P003073 P003086 P003138 P179141 P003047 P003030 P003088 P003046 P003139 P003095 P003115 P512210\n",
    "P175834 P171821 P176360 P159217 P144712 P003032 P165052 P170835 P111133 P111150 P003102 P003039 P003064 P003085\n",
    "P178389 P003023 P003038 P003084 P131120\"\"\".split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data WB Project #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wb_projects length: 24\n"
     ]
    }
   ],
   "source": [
    "# 1) Load the \"World Bank Projects\" sheet from all.xlsx\n",
    "df_wbp = pd.read_csv(\"wb_data_raw/wbp.csv\")\n",
    "\n",
    "# 2) Normalize the 'id' column (strip spaces, uppercase) to match your IDS list reliably\n",
    "df_wbp[\"id_norm\"] = df_wbp[\"id\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 3) Keep only rows whose id is in IDS\n",
    "wb_projects = df_wbp[df_wbp[\"id_norm\"].isin(IDS)].copy()\n",
    "\n",
    "# 4) Keep only active projects\n",
    "wb_projects = wb_projects[wb_projects[\"status\"] == \"Active\"]\n",
    "ids_active = wb_projects[\"id\"].unique().tolist() # creating list with active projects\n",
    "\n",
    "# 5) Basic outputs\n",
    "print(\"wb_projects length:\", len(wb_projects))\n",
    "\n",
    "# 6) Saving as a .csv\n",
    "wb_projects.to_csv(\"wb_data_clean/wb_projects.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data Themes #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wb_themes length: 483\n",
      "Missing IDs (in ids_active but not in wb_themes): 0\n"
     ]
    }
   ],
   "source": [
    "df_th = pd.read_csv(\"wb_data_raw/themes.csv\")\n",
    "\n",
    "# 2) Normalize the 'Project ID' column (strip spaces, uppercase) to match your ids_active list reliably\n",
    "df_th[\"id_norm\"] = df_th[\"Project ID\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 3) Keep only rows whose id is in ids_active\n",
    "wb_themes = df_th[df_th[\"id_norm\"].isin(ids_active)].copy()\n",
    "\n",
    "# 4) Basic outputs\n",
    "print(\"wb_themes length:\", len(wb_themes))\n",
    "\n",
    "# 5) Which IDs are in ids_active but NOT in wb_themes?\n",
    "wb_ids_found = set(wb_themes[\"id_norm\"])\n",
    "missing_from_sheet = [pid for pid in ids_active if pid not in wb_ids_found]\n",
    "print(\"Missing IDs (in ids_active but not in wb_themes):\", len(missing_from_sheet))\n",
    "\n",
    "# 6) Saving as a .csv\n",
    "wb_themes.to_csv(\"wb_data_clean/wb_themes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data Sectors #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wb_sectors length: 76\n",
      "Missing IDs (in ids_active but not in wb_sectors): 0\n"
     ]
    }
   ],
   "source": [
    "df_se = pd.read_csv(\"wb_data_raw/sector.csv\")\n",
    "\n",
    "# 2) Normalize the 'Project ID' column (strip spaces, uppercase) to match your ids_active list reliably\n",
    "df_se[\"id_norm\"] = df_se[\"Project ID\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 3) Keep only rows whose id is in ids_active\n",
    "wb_sectors = df_se[df_se[\"id_norm\"].isin(ids_active)].copy()\n",
    "\n",
    "# 4) Basic outputs\n",
    "print(\"wb_sectors length:\", len(wb_sectors))\n",
    "\n",
    "# 5) Which IDs are in ids_active but NOT in wb_sectors?\n",
    "wb_ids_found = set(wb_sectors[\"id_norm\"])\n",
    "missing_from_sheet = [pid for pid in ids_active if pid not in wb_ids_found]\n",
    "print(\"Missing IDs (in ids_active but not in wb_sectors):\", len(missing_from_sheet))\n",
    "\n",
    "# 6) Saving as a .csv\n",
    "wb_sectors.to_csv(\"wb_data_clean/wb_sectors.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data Geo Location #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wb_geo length: 138\n",
      "Missing IDs (in ids_active but not in wb_geo): 2\n",
      "['P160320', 'P507861']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/9_97t00x0_q65qbwvxmx9jgw0000gn/T/ipykernel_50044/679690237.py:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_geo = pd.read_csv(\"wb_data_raw/geo.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_geo = pd.read_csv(\"wb_data_raw/geo.csv\")\n",
    "\n",
    "# 2) Normalize the 'Project ID' column (strip spaces, uppercase) to match your ids_active list reliably\n",
    "df_geo[\"id_norm\"] = df_geo[\"Project ID\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 3) Keep only rows whose id is in ids_active\n",
    "wb_geo = df_geo[df_geo[\"id_norm\"].isin(ids_active)].copy()\n",
    "\n",
    "# 4) Basic outputs\n",
    "print(\"wb_geo length:\", len(wb_geo))\n",
    "\n",
    "# 5) Which IDs are in ids_active but NOT in wb_geo?\n",
    "wb_ids_found = set(wb_geo[\"id_norm\"])\n",
    "missing_from_sheet = [pid for pid in ids_active if pid not in wb_ids_found]\n",
    "print(\"Missing IDs (in ids_active but not in wb_geo):\", len(missing_from_sheet))\n",
    "print(missing_from_sheet[:25])  # preview first 25\n",
    "\n",
    "# 6) Saving as a .csv\n",
    "wb_geo.to_csv(\"wb_data_clean/wb_geo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data Financers #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wb_financers length: 45\n",
      "Missing IDs (in ids_active but not in wb_financers): 0\n"
     ]
    }
   ],
   "source": [
    "df_financers = pd.read_csv(\"wb_data_raw/financers.csv\")\n",
    "\n",
    "# 2) Normalize the 'Project ID' column (strip spaces, uppercase) to match your ids_active list reliably\n",
    "df_financers[\"id_norm\"] = df_financers[\"Project\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 3) Keep only rows whose id is in ids_active\n",
    "wb_financers = df_financers[df_financers[\"id_norm\"].isin(ids_active)].copy()\n",
    "\n",
    "# 4) Basic outputs\n",
    "print(\"wb_financers length:\", len(wb_financers))\n",
    "\n",
    "# 5) Which IDs are in ids_active but NOT in wb_financers?\n",
    "wb_ids_found = set(wb_financers[\"id_norm\"])\n",
    "missing_from_sheet = [pid for pid in ids_active if pid not in wb_ids_found]\n",
    "print(\"Missing IDs (in ids_active but not in wb_financers):\", len(missing_from_sheet))\n",
    "\n",
    "# 6) Saving as a .csv\n",
    "wb_financers.to_csv(\"wb_data_clean/wb_financers.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
